{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interract with LLM easily with LangChain4j and Ollama.\n",
    "After you've installed Ollama, we can add the LangChain4j dependency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@file:DependsOn(\"dev.langchain4j:langchain4j-ollama:0.32.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's ask a simple question to LLM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital city of Japan is Tokyo, located in the eastern part of the country.\n"
     ]
    }
   ],
   "source": [
    "import dev.langchain4j.model.ollama.OllamaChatModel\n",
    "\n",
    "val modelName = \"tinyllama\"\n",
    "val builder = OllamaChatModel.builder()\n",
    "    .baseUrl(\"http://localhost:11434/v1/\")\n",
    "    .modelName(modelName)\n",
    "val smallModel = builder.build()\n",
    "\n",
    "val answer = smallModel.generate(\"What is the capital city of Japan?\")\n",
    "println(answer) // Tokyo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use LLM as a translator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Gracias!\n",
      "\n",
      "Traducción del inglés para español (español)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val translation = smallModel.generate(\"Please translate 'Thank you' to Spanish\")\n",
    "println(translation) // Gracias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final example, a simple classification.\n",
    "This time, we need to provide `langchain4j` library to use `AiServices`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@file:DependsOn(\"dev.langchain4j:langchain4j:0.32.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we need a bigger model, I use `gemma2:2b` for this example.\n",
    "Don't forget to pull the image first, using `ollama pull gemma2:2b` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val biggerModel = builder.modelName(\"gemma2:2b\").build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then pass the `biggerModel` to create implementation for `SentimentAnalyzer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n",
      "false\n"
     ]
    }
   ],
   "source": [
    "import dev.langchain4j.service.AiServices\n",
    "import dev.langchain4j.service.UserMessage\n",
    "\n",
    "enum class Sentiment {\n",
    "    POSITIVE, NEUTRAL, NEGATIVE\n",
    "}\n",
    "\n",
    "interface SentimentAnalyzer {\n",
    "    @UserMessage(\"Analyze sentiment of {{it}}\")\n",
    "    fun analyzeSentimentOf(text: String): Sentiment\n",
    "\n",
    "    @UserMessage(\"Does {{it}} have a positive sentiment?\")\n",
    "    fun isPositive(text: String): Boolean\n",
    "}\n",
    "\n",
    "val sentimentAnalyzer = AiServices.create(SentimentAnalyzer::class.java, biggerModel)\n",
    "\n",
    "val sentiment = sentimentAnalyzer.analyzeSentimentOf(\"It is good!\")\n",
    "println(sentiment) // POSITIVE\n",
    "\n",
    "val positive = sentimentAnalyzer.isPositive(\"It is bad!\")\n",
    "println(positive) // false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You can see other examples in this [langchain4j-examples](https://github.com/langchain4j/langchain4j-examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "codemirror_mode": "text/x-kotlin",
   "file_extension": ".kt",
   "mimetype": "text/x-kotlin",
   "name": "kotlin",
   "nbconvert_exporter": "",
   "pygments_lexer": "kotlin",
   "version": "1.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
